# -*- coding: utf-8 -*-
"""Exercises.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Pratik25priyanshu20/sas-viya-quick-start/blob/main/Exercises.ipynb
"""

#Exercise_1_analysis_of_movies
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


file_path = r"/content/data[1].csv"
data = pd.read_csv(file_path)
print("Dataset Overview:")
print(data.info())  #
print("\nSummary Statistics:")
print(data.describe())

print("\nMissing Values:")
print(data.isnull().sum())


numerical_cols = data.select_dtypes(include=[np.number]).columns

for col in numerical_cols:
    print(f"\n--- {col} ---")
    print(f"Mean: {data[col].mean()}")
    print(f"Median: {data[col].median()}")
    print(f"Mode: {data[col].mode().iloc[0]}")
    print(f"Variance: {data[col].var()}")
    print(f"Standard Deviation: {data[col].std()}")
    print(f"IQR: {data[col].quantile(0.75) - data[col].quantile(0.25)}")


for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.histplot(data[col], kde=True, bins=30)
    plt.title(f"Distribution of {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()


for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x=data[col])
    plt.title(f"Boxplot of {col}")
    plt.xlabel(col)
    plt.show()


plt.figure(figsize=(10, 8))
sns.heatmap(data[numerical_cols].corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

if len(numerical_cols) > 1:
    plt.figure(figsize=(8, 5))
    sns.scatterplot(x=numerical_cols[0], y=numerical_cols[1], data=data)
    plt.title(f"Scatter Plot of {numerical_cols[0]} vs {numerical_cols[1]}")
    plt.xlabel(numerical_cols[0])
    plt.ylabel(numerical_cols[1])
    plt.show()


categorical_cols = data.select_dtypes(include=['object', 'category']).columns
for col in categorical_cols:
    plt.figure(figsize=(8, 5))
    data[col].value_counts().plot(kind='bar', color='skyblue')
    plt.title(f"Bar Chart of {col}")
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.show()

#EXERCISE_2
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns


data = sns.load_dataset("iris")


print(data.describe())
print(data.head())


def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1                   # Interquartile range
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    filtered_data = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return filtered_data


cleaned_data = remove_outliers(data, 'sepal_length')


def systematic_sampling(data, fraction):
    step = int(1 / fraction)
    sampled_data = data.iloc[::step]
    return sampled_data



systematic_sample = systematic_sampling(cleaned_data, 0.2)



plt.figure(figsize=(12, 6))


plt.subplot(1, 3, 1)
plt.hist(data['sepal_length'], bins=15, color='red', edgecolor='black', alpha=0.7, )
plt.title("Original Dataset")
plt.xlabel("Sepal Length")
plt.ylabel("Density")



plt.subplot(1, 3, 2)
plt.hist(systematic_sample['sepal_length'], bins=15, color='blue', edgecolor='black', alpha=0.7, )
plt.title("Cleaned Dataset (No Outliers)")
plt.xlabel("Sepal Length")
plt.ylabel("Density")



plt.tight_layout()
plt.show()

#EXERCISE_3

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import ttest_1samp, f_oneway, norm,pearsonr,ttest_ind
from sklearn.datasets import load_iris



#iris= sns.load_dataset("iris")
iris = load_iris()

#versicolor_data = iris[iris['species'] == 'versicolor']['sepal_length']

iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)
iris_df['species']= [iris.target_names[i] for i in iris.target]

iris_df.columns =['sepal_length','sepal_width','petal_length','petal_width','species']

versicolor_petal_length  = iris_df[iris_df['species']=='versicolor']['petal_length']
virginica_petal_length = iris_df[iris_df['species']=='virginica']['petal_length']

t_stat, p_value = ttest_1samp(versicolor_petal_length, virginica_petal_length.mean())
#why not ttest_ind?
print(f"T-statistics: {t_stat}")
print(f"P-Value: {p_value}")





if p_value < 0.05:
    print("Reject the null hypothesis: There is a significant difference in petal length between versicolor and virginica.")
else:
    print("Fail to reject the null hypothesis: There is no significant difference in petal length between versicolor and virginica.")

    sample_mean = np.mean(versicolor_petal_length)
    std_dev = 0.35
    n= len(versicolor_petal_length)

    confidence_level = 0.95
    #z_value = stats.norm.ppf(1 - (1 - 0.95) / 2)
    margin_of_error = 1.96 * (std_dev / np.sqrt(n))
    confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)

    print(f"Sample Mean: {sample_mean:.2f}")
    print(f"Sample Standard Deviation: {std_dev:.3f}")





    setosa_petal_width= iris_df[iris_df['species']=='setosa']['petal_width']
    versicolor_petal_width=iris_df[iris_df['species']=='versicolor']['petal_width']
    virginica_petal_width=iris_df[iris_df['species']=='virginica']['petal_width']

    f_stat, p_value = f_oneway(setosa_petal_width, versicolor_petal_width, virginica_petal_width)

    print(f"F-statistics: {f_stat}")
    print(f"P-Value: {p_value}")

    if p_value < 0.05:
        print("Reject the null hypothesis: There is a significant difference in petal width between the three species.")
    else:
        print("Fail to reject the null hypothesis: There is no significant difference in petal width between the three species.")




sepal_length = iris_df['sepal_length']
petal_length = iris_df['petal_length']


corr_coeff, corr_p_value = pearsonr(iris_df['sepal_length'],iris_df['petal_length'])

print(f"Correlation Coefficient: {corr_coeff}")
print(f"P-Value: {corr_p_value}")

#corr=iris.iloc[:,:-1].corr()
#sns.heatmap(corr,annot=True,cmap="coolwarm")
#plt.title("correlation heatmap")

#plt.show()

